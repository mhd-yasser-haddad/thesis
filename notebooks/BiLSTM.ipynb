{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yasser\\anaconda3\\envs\\thesis\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchcrf import CRF\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from datasets import load_from_disk\n",
    "from reference_parsing.config import (LABEL2ID)\n",
    "\n",
    "from reference_parsing.utils.data_preparation import prepare_bilstm_crf_data, collate_bilstm_crf\n",
    "from reference_parsing.embeddings.HandFeatureEmbedding import  HandFeatureEmbedding\n",
    "from reference_parsing.embeddings.BytePairReferenceEmbedding import BytePairReferenceEmbedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_dataset = load_from_disk(\"./datasets/prepared_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_emb = BytePairReferenceEmbedding()\n",
    "hand_emb = HandFeatureEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReferenceDataset(Dataset):\n",
    "    def __init__(self, X_bpe, X_hand, Y):\n",
    "        self.X_bpe = X_bpe\n",
    "        self.X_hand = X_hand\n",
    "        self.Y = Y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X_bpe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X_bpe[idx], self.X_hand[idx], self.Y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = LABEL2ID\n",
    "id2label = {v: k for k, v in label2id.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_5mil = prepared_dataset[\"train\"].select(range(5000000))\n",
    "valid_5mil = prepared_dataset[\"valid\"].select(range(200000))\n",
    "test_5mil = prepared_dataset[\"test\"].select(range(200000)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bpe, X_hand, Y = prepare_bilstm_crf_data(bp_emb, hand_emb, train_5mil)\n",
    "train_ds = ReferenceDataset(X_bpe, X_hand, Y)\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True,\n",
    "                          collate_fn=lambda batch: collate_bilstm_crf(batch, label2id, hand_emb.get_hand_feature_vocab()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bpe, X_hand, Y = prepare_bilstm_crf_data(bp_emb, hand_emb, valid_5mil)\n",
    "valid_ds = ReferenceDataset(X_bpe, X_hand, Y)\n",
    "valid_loader = DataLoader(valid_ds, batch_size=32, shuffle=True,\n",
    "                          collate_fn=lambda batch: collate_bilstm_crf(batch, label2id, hand_emb.get_hand_feature_vocab()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bpe, X_hand, Y = prepare_bilstm_crf_data(bp_emb, hand_emb, test_5mil)\n",
    "test_ds = ReferenceDataset(X_bpe, X_hand, Y)\n",
    "test_loader = DataLoader(test_ds, batch_size=32, shuffle=True,\n",
    "                          collate_fn=lambda batch: collate_bilstm_crf(batch, label2id, hand_emb.get_hand_feature_vocab()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiLSTM - Hand Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMCRFModel(nn.Module):\n",
    "    def __init__(self, bpe_dim, lstm_hidden_dim, hand_vocab_size, hand_emb_dim, num_tags, dropout_rate=0.5):\n",
    "        super(BiLSTMCRFModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=bpe_dim, hidden_size=lstm_hidden_dim,\n",
    "                            batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.hand_emb = nn.Embedding(hand_vocab_size, hand_emb_dim)\n",
    "        self.hand_proj = nn.Linear(hand_emb_dim, 2 * lstm_hidden_dim)\n",
    "        self.classifier = nn.Linear(2 * lstm_hidden_dim, num_tags)\n",
    "        self.crf = CRF(num_tags, batch_first=True)\n",
    "\n",
    "    def forward(self, bpe_embeddings, hand_indices, tags=None, mask=None):\n",
    "        lstm_out, _ = self.lstm(bpe_embeddings)\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "        hand_emb_out = self.hand_emb(hand_indices)\n",
    "        hand_emb_out = self.dropout(hand_emb_out)\n",
    "        hand_proj = self.hand_proj(hand_emb_out)\n",
    "        fused = lstm_out + hand_proj\n",
    "        fused = self.dropout(fused)\n",
    "        emissions = self.classifier(fused)\n",
    "        if tags is not None:\n",
    "            loss = -self.crf(emissions, tags, mask=mask, reduction='mean')\n",
    "            return loss, emissions\n",
    "        else:\n",
    "            predictions = self.crf.decode(emissions, mask=mask)\n",
    "            return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, optimizer, num_epochs, device):\n",
    "    best_val_loss = float('inf')\n",
    "    model.train()\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        total_loss = 0.0\n",
    "        for batch in train_loader:\n",
    "            bpe_inputs, hand_inputs, tags, mask = batch\n",
    "            bpe_inputs = bpe_inputs.to(device)\n",
    "            hand_inputs = hand_inputs.to(device)\n",
    "            tags = tags.to(device)\n",
    "            mask = mask.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss, _ = model(bpe_inputs, hand_inputs, tags, mask)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch}/{num_epochs}: Training Loss = {avg_loss:.4f}\")\n",
    "        \n",
    "        # Validation step\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                bpe_inputs, hand_inputs, tags, mask = batch\n",
    "                bpe_inputs = bpe_inputs.to(device)\n",
    "                hand_inputs = hand_inputs.to(device)\n",
    "                tags = tags.to(device)\n",
    "                mask = mask.to(device)\n",
    "                loss, _ = model(bpe_inputs, hand_inputs, tags, mask)\n",
    "                total_val_loss += loss.item()\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        print(f\"Epoch {epoch}/{num_epochs}: Validation Loss = {avg_val_loss:.4f}\")\n",
    "        \n",
    "        # Save the model only if the validation loss improved\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), f\"models/bilstm_5mil/bilstm_crf_best.pt\")\n",
    "            print(f\"Model saved at epoch {epoch} with validation loss {avg_val_loss:.4f}\")\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(sequences):\n",
    "    return [label for seq in sequences for label in seq]\n",
    "\n",
    "def evaluate_and_report(model, test_loader, label2id, id2label):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_true = []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            bpe_inputs, hand_inputs, tags, mask = batch\n",
    "            predictions = model(bpe_inputs, hand_inputs, mask=mask)\n",
    "            all_predictions.extend(predictions)\n",
    "            all_true.extend(tags.cpu().tolist())\n",
    "    \n",
    "    y_pred_flat = flatten(all_predictions)\n",
    "    y_true_flat = flatten(all_true)\n",
    "\n",
    "    y_true_flat_filtered = [x for x in y_true_flat if x != -1]\n",
    "    y_pred_flat_filtered = [x for x in y_pred_flat if x != -1]\n",
    "\n",
    "    y_true_labels = [id2label[idx] for idx in y_true_flat_filtered]\n",
    "    y_pred_labels = [id2label[idx] for idx in y_pred_flat_filtered]\n",
    "\n",
    "    label_order = list(label2id.keys())\n",
    "\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_true_labels, y_pred_labels, labels=label_order, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe_dim = 600\n",
    "lstm_hidden_dim = 128\n",
    "hand_vocab_size = len(hand_emb.get_hand_feature_vocab())\n",
    "hand_emb_dim = 50\n",
    "num_tags = 26\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "bilstm_crf_5mil = BiLSTMCRFModel(bpe_dim, lstm_hidden_dim, hand_vocab_size, hand_emb_dim, num_tags)\n",
    "optimizer = optim.AdamW(bilstm_crf_5mil.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: Training Loss = 149.4699\n",
      "Epoch 1/50: Validation Loss = 102.7207\n",
      "Model saved at epoch 1 with validation loss 102.7207\n",
      "Epoch 2/50: Training Loss = 101.8513\n",
      "Epoch 2/50: Validation Loss = 91.2631\n",
      "Model saved at epoch 2 with validation loss 91.2631\n",
      "Epoch 3/50: Training Loss = 82.3033\n",
      "Epoch 3/50: Validation Loss = 85.1576\n",
      "Model saved at epoch 3 with validation loss 85.1576\n",
      "Epoch 4/50: Training Loss = 79.9737\n",
      "Epoch 4/50: Validation Loss = 75.8468\n",
      "Model saved at epoch 4 with validation loss 75.8468\n",
      "Epoch 5/50: Training Loss = 71.6131\n",
      "Epoch 5/50: Validation Loss = 68.7395\n",
      "Model saved at epoch 5 with validation loss 68.7395\n",
      "Epoch 6/50: Training Loss = 64.2328\n",
      "Epoch 6/50: Validation Loss = 61.9641\n",
      "Model saved at epoch 6 with validation loss 61.9641\n",
      "Epoch 7/50: Training Loss = 58.1300\n",
      "Epoch 7/50: Validation Loss = 55.0834\n",
      "Model saved at epoch 7 with validation loss 55.0834\n",
      "Epoch 8/50: Training Loss = 51.9631\n",
      "Epoch 8/50: Validation Loss = 49.4444\n",
      "Model saved at epoch 8 with validation loss 49.4444\n",
      "Epoch 9/50: Training Loss = 47.1079\n",
      "Epoch 9/50: Validation Loss = 45.6644\n",
      "Model saved at epoch 9 with validation loss 45.6644\n",
      "Epoch 10/50: Training Loss = 44.3993\n",
      "Epoch 10/50: Validation Loss = 42.9144\n",
      "Model saved at epoch 10 with validation loss 42.9144\n",
      "Epoch 11/50: Training Loss = 38.9173\n",
      "Epoch 11/50: Validation Loss = 41.0166\n",
      "Model saved at epoch 11 with validation loss 41.0166\n",
      "Epoch 12/50: Training Loss = 36.4009\n",
      "Epoch 12/50: Validation Loss = 39.8778\n",
      "Model saved at epoch 12 with validation loss 39.8778\n",
      "Epoch 13/50: Training Loss = 34.3940\n",
      "Epoch 13/50: Validation Loss = 39.3353\n",
      "Model saved at epoch 13 with validation loss 39.3353\n",
      "Epoch 14/50: Training Loss = 30.3151\n",
      "Epoch 14/50: Validation Loss = 38.9063\n",
      "Model saved at epoch 14 with validation loss 38.9063\n",
      "Epoch 15/50: Training Loss = 28.0471\n",
      "Epoch 15/50: Validation Loss = 38.0998\n",
      "Model saved at epoch 15 with validation loss 38.0998\n",
      "Epoch 16/50: Training Loss = 25.9772\n",
      "Epoch 16/50: Validation Loss = 36.7117\n",
      "Model saved at epoch 16 with validation loss 36.7117\n",
      "Epoch 17/50: Training Loss = 24.6731\n",
      "Epoch 17/50: Validation Loss = 34.5563\n",
      "Model saved at epoch 17 with validation loss 34.5563\n",
      "Epoch 18/50: Training Loss = 22.4262\n",
      "Epoch 18/50: Validation Loss = 31.9681\n",
      "Model saved at epoch 18 with validation loss 31.9681\n",
      "Epoch 19/50: Training Loss = 19.2747\n",
      "Epoch 19/50: Validation Loss = 29.2134\n",
      "Model saved at epoch 19 with validation loss 29.2134\n",
      "Epoch 20/50: Training Loss = 18.5308\n",
      "Epoch 20/50: Validation Loss = 26.6458\n",
      "Model saved at epoch 20 with validation loss 26.6458\n",
      "Epoch 21/50: Training Loss = 17.2510\n",
      "Epoch 21/50: Validation Loss = 24.8173\n",
      "Model saved at epoch 21 with validation loss 24.8173\n",
      "Epoch 22/50: Training Loss = 16.9660\n",
      "Epoch 22/50: Validation Loss = 23.6717\n",
      "Model saved at epoch 22 with validation loss 23.6717\n",
      "Epoch 23/50: Training Loss = 14.2315\n",
      "Epoch 23/50: Validation Loss = 22.9289\n",
      "Model saved at epoch 23 with validation loss 22.9289\n",
      "Epoch 24/50: Training Loss = 12.9593\n",
      "Epoch 24/50: Validation Loss = 22.3640\n",
      "Model saved at epoch 24 with validation loss 22.3640\n",
      "Epoch 25/50: Training Loss = 12.8033\n",
      "Epoch 25/50: Validation Loss = 22.2723\n",
      "Model saved at epoch 25 with validation loss 22.2723\n",
      "Epoch 26/50: Training Loss = 11.6168\n",
      "Epoch 26/50: Validation Loss = 22.3838\n",
      "Epoch 27/50: Training Loss = 10.7869\n",
      "Epoch 27/50: Validation Loss = 22.5602\n",
      "Epoch 28/50: Training Loss = 9.5609\n",
      "Epoch 28/50: Validation Loss = 22.5703\n",
      "Epoch 29/50: Training Loss = 9.5195\n",
      "Epoch 29/50: Validation Loss = 22.4049\n",
      "Epoch 30/50: Training Loss = 9.5511\n",
      "Epoch 30/50: Validation Loss = 21.7185\n",
      "Model saved at epoch 30 with validation loss 21.7185\n",
      "Epoch 31/50: Training Loss = 8.9393\n",
      "Epoch 31/50: Validation Loss = 20.9676\n",
      "Model saved at epoch 31 with validation loss 20.9676\n",
      "Epoch 32/50: Training Loss = 8.0279\n",
      "Epoch 32/50: Validation Loss = 20.1165\n",
      "Model saved at epoch 32 with validation loss 20.1165\n",
      "Epoch 33/50: Training Loss = 7.6181\n",
      "Epoch 33/50: Validation Loss = 19.2794\n",
      "Model saved at epoch 33 with validation loss 19.2794\n",
      "Epoch 34/50: Training Loss = 6.9770\n",
      "Epoch 34/50: Validation Loss = 18.6861\n",
      "Model saved at epoch 34 with validation loss 18.6861\n",
      "Epoch 35/50: Training Loss = 6.2991\n",
      "Epoch 35/50: Validation Loss = 18.0507\n",
      "Model saved at epoch 35 with validation loss 18.0507\n",
      "Epoch 36/50: Training Loss = 6.5041\n",
      "Epoch 36/50: Validation Loss = 17.5157\n",
      "Model saved at epoch 36 with validation loss 17.5157\n",
      "Epoch 37/50: Training Loss = 6.0792\n",
      "Epoch 37/50: Validation Loss = 17.2174\n",
      "Model saved at epoch 37 with validation loss 17.2174\n",
      "Epoch 38/50: Training Loss = 6.2195\n",
      "Epoch 38/50: Validation Loss = 16.9921\n",
      "Model saved at epoch 38 with validation loss 16.9921\n",
      "Epoch 39/50: Training Loss = 4.8108\n",
      "Epoch 39/50: Validation Loss = 16.7729\n",
      "Model saved at epoch 39 with validation loss 16.7729\n",
      "Epoch 40/50: Training Loss = 5.4596\n",
      "Epoch 40/50: Validation Loss = 16.5574\n",
      "Model saved at epoch 40 with validation loss 16.5574\n",
      "Epoch 41/50: Training Loss = 4.3490\n",
      "Epoch 41/50: Validation Loss = 16.4782\n",
      "Model saved at epoch 41 with validation loss 16.4782\n",
      "Epoch 42/50: Training Loss = 4.4272\n",
      "Epoch 42/50: Validation Loss = 16.3893\n",
      "Model saved at epoch 42 with validation loss 16.3893\n",
      "Epoch 43/50: Training Loss = 4.2666\n",
      "Epoch 43/50: Validation Loss = 16.4486\n",
      "Epoch 44/50: Training Loss = 4.4528\n",
      "Epoch 44/50: Validation Loss = 16.4640\n",
      "Epoch 45/50: Training Loss = 2.9684\n",
      "Epoch 45/50: Validation Loss = 16.5547\n",
      "Epoch 46/50: Training Loss = 3.9943\n",
      "Epoch 46/50: Validation Loss = 16.4929\n",
      "Epoch 47/50: Training Loss = 3.3214\n",
      "Epoch 47/50: Validation Loss = 16.3628\n",
      "Model saved at epoch 47 with validation loss 16.3628\n",
      "Epoch 48/50: Training Loss = 3.5199\n",
      "Epoch 48/50: Validation Loss = 16.0645\n",
      "Model saved at epoch 48 with validation loss 16.0645\n",
      "Epoch 49/50: Training Loss = 3.4781\n",
      "Epoch 49/50: Validation Loss = 15.8491\n",
      "Model saved at epoch 49 with validation loss 15.8491\n",
      "Epoch 50/50: Training Loss = 1.9472\n",
      "Epoch 50/50: Validation Loss = 15.7623\n",
      "Model saved at epoch 50 with validation loss 15.7623\n"
     ]
    }
   ],
   "source": [
    "bilstm_crf_5mil = train_model(bilstm_crf_5mil, train_loader, valid_loader, optimizer, 50, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score      support\n",
      "\n",
      "         B-AUTHOR       0.86      0.86      0.86       190515\n",
      "         I-AUTHOR       0.90      0.97      0.93      1735612\n",
      "           B-YEAR       0.98      0.88      0.93       172556\n",
      "           I-YEAR       0.98      0.90      0.94         1350\n",
      "          B-TITLE       0.82      0.90      0.86      1815762\n",
      "          I-TITLE       0.78      0.99      0.87     18249721\n",
      "B-CONTAINER-TITLE       0.44      0.40      0.42       133714\n",
      "I-CONTAINER-TITLE       0.84      0.44      0.58      1100358\n",
      "         B-VOLUME       0.62      0.98      0.76        39419\n",
      "         I-VOLUME       0.85      0.95      0.90          155\n",
      "          B-ISSUE       0.67      0.98      0.80        13557\n",
      "          I-ISSUE       0.85      0.98      0.91          343\n",
      "           B-PAGE       0.85      0.98      0.91       157135\n",
      "           I-PAGE       0.90      0.97      0.93        29258\n",
      "           B-ISBN       0.97      0.83      0.89        45327\n",
      "           B-ISSN       0.95      0.85      0.90        10951\n",
      "      B-PUBLISHER       0.75      0.75      0.75        69554\n",
      "      I-PUBLISHER       0.99      0.82      0.90         4959\n",
      "            B-DOI       0.80      0.88      0.84        82176\n",
      "            B-URL       0.99      0.99      0.99       120729\n",
      "            I-URL       0.99      0.99      0.99         3008\n",
      "                O       0.88      0.78      0.83      3997028\n",
      "           B-PUNC       0.99      0.98      0.98      3125747\n",
      "\n",
      "         accuracy                           0.88     31098934\n",
      "        macro avg       0.85      0.87      0.85     31098934\n",
      "     weighted avg       0.83      0.93      0.87     31098934\n"
     ]
    }
   ],
   "source": [
    "evaluate_and_report(bilstm_crf_5mil, test_loader, label2id, id2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiLSTM - No Hand Featurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMCRFModelNoHand(nn.Module):\n",
    "    def __init__(self, bpe_dim, lstm_hidden_dim, num_tags, dropout_rate=0.5):\n",
    "        super(BiLSTMCRFModelNoHand, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=bpe_dim, hidden_size=lstm_hidden_dim,\n",
    "                            batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.classifier = nn.Linear(2 * lstm_hidden_dim, num_tags)\n",
    "        self.crf = CRF(num_tags, batch_first=True)\n",
    "\n",
    "    def forward(self, bpe_embeddings, tags=None, mask=None):\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "        emissions = self.classifier(lstm_out)\n",
    "        \n",
    "        if tags is not None:\n",
    "            loss = -self.crf(emissions, tags, mask=mask, reduction='mean')\n",
    "            return loss, emissions\n",
    "        else:\n",
    "            predictions = self.crf.decode(emissions, mask=mask)\n",
    "            return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_no_hand(model, train_loader, val_loader, optimizer, num_epochs, device):\n",
    "    best_val_loss = float('inf')\n",
    "    model.train()\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        total_loss = 0.0\n",
    "        for batch in train_loader:\n",
    "            # Each batch now is a tuple: (bpe_embeddings, tags, mask)\n",
    "            bpe_inputs, _, tags, mask = batch\n",
    "            bpe_inputs = bpe_inputs.to(device)\n",
    "            tags = tags.to(device)\n",
    "            mask = mask.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss, _ = model(bpe_inputs, tags=tags, mask=mask)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch}/{num_epochs}: Training Loss = {avg_loss:.4f}\")\n",
    "        \n",
    "        # Validation step\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                bpe_inputs, _, tags, mask = batch\n",
    "                bpe_inputs = bpe_inputs.to(device)\n",
    "                tags = tags.to(device)\n",
    "                mask = mask.to(device)\n",
    "                loss, _ = model(bpe_inputs, tags=tags, mask=mask)\n",
    "                total_val_loss += loss.item()\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        print(f\"Epoch {epoch}/{num_epochs}: Validation Loss = {avg_val_loss:.4f}\")\n",
    "        \n",
    "        # Save model checkpoint if validation loss improves.\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), \"models/bilstm_crf_no_hand_best.pt\")\n",
    "            print(f\"Model saved at epoch {epoch} with validation loss {avg_val_loss:.4f}\")\n",
    "        \n",
    "        model.train()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_report_no_hand(model, test_loader, label2id, id2label):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_true = []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            bpe_inputs, _, tags, mask = batch\n",
    "            bpe_inputs = bpe_inputs\n",
    "            mask = mask\n",
    "            predictions = model(bpe_inputs, mask=mask)\n",
    "            all_predictions.extend(predictions)\n",
    "            all_true.extend(tags.cpu().tolist())\n",
    "    \n",
    "    y_pred_flat = flatten(all_predictions)\n",
    "    y_true_flat = flatten(all_true)\n",
    "    \n",
    "    y_true_flat_filtered = [x for x in y_true_flat if x != -1]\n",
    "    y_pred_flat_filtered = [x for x in y_pred_flat if x != -1]\n",
    "    \n",
    "    y_true_labels = [id2label[idx] for idx in y_true_flat_filtered]\n",
    "    y_pred_labels = [id2label[idx] for idx in y_pred_flat_filtered]\n",
    "\n",
    "    label_order = list(label2id.keys())\n",
    "    \n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_true_labels, y_pred_labels, labels=label_order, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe_dim = 600\n",
    "lstm_hidden_dim = 128\n",
    "num_tags = 26\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "bilstm_crf_5mil_no_hand = BiLSTMCRFModelNoHand(bpe_dim, lstm_hidden_dim, num_tags)\n",
    "optimizer = optim.AdamW(bilstm_crf_5mil_no_hand.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: Training Loss = 146.3255\n",
      "Epoch 1/50: Validation Loss = 123.7872\n",
      "Model saved at epoch 1 with validation loss 123.7872\n",
      "Epoch 2/50: Training Loss = 117.0938\n",
      "Epoch 2/50: Validation Loss = 103.2188\n",
      "Model saved at epoch 2 with validation loss 103.2188\n",
      "Epoch 3/50: Training Loss = 91.2532\n",
      "Epoch 3/50: Validation Loss = 86.7035\n",
      "Model saved at epoch 3 with validation loss 86.7035\n",
      "Epoch 4/50: Training Loss = 73.6974\n",
      "Epoch 4/50: Validation Loss = 75.8566\n",
      "Model saved at epoch 4 with validation loss 75.8566\n",
      "Epoch 5/50: Training Loss = 64.7248\n",
      "Epoch 5/50: Validation Loss = 66.9796\n",
      "Model saved at epoch 5 with validation loss 66.9796\n",
      "Epoch 6/50: Training Loss = 57.2982\n",
      "Epoch 6/50: Validation Loss = 59.8148\n",
      "Model saved at epoch 6 with validation loss 59.8148\n",
      "Epoch 7/50: Training Loss = 50.7620\n",
      "Epoch 7/50: Validation Loss = 54.0641\n",
      "Model saved at epoch 7 with validation loss 54.0641\n",
      "Epoch 8/50: Training Loss = 43.3658\n",
      "Epoch 8/50: Validation Loss = 48.8672\n",
      "Model saved at epoch 8 with validation loss 48.8672\n",
      "Epoch 9/50: Training Loss = 38.3514\n",
      "Epoch 9/50: Validation Loss = 44.0016\n",
      "Model saved at epoch 9 with validation loss 44.0016\n",
      "Epoch 10/50: Training Loss = 33.6333\n",
      "Epoch 10/50: Validation Loss = 39.7809\n",
      "Model saved at epoch 10 with validation loss 39.7809\n",
      "Epoch 11/50: Training Loss = 30.4225\n",
      "Epoch 11/50: Validation Loss = 36.3691\n",
      "Model saved at epoch 11 with validation loss 36.3691\n",
      "Epoch 12/50: Training Loss = 26.6944\n",
      "Epoch 12/50: Validation Loss = 33.6535\n",
      "Model saved at epoch 12 with validation loss 33.6535\n",
      "Epoch 13/50: Training Loss = 24.2368\n",
      "Epoch 13/50: Validation Loss = 31.5524\n",
      "Model saved at epoch 13 with validation loss 31.5524\n",
      "Epoch 14/50: Training Loss = 22.0257\n",
      "Epoch 14/50: Validation Loss = 30.0181\n",
      "Model saved at epoch 14 with validation loss 30.0181\n",
      "Epoch 15/50: Training Loss = 20.3734\n",
      "Epoch 15/50: Validation Loss = 28.8037\n",
      "Model saved at epoch 15 with validation loss 28.8037\n",
      "Epoch 16/50: Training Loss = 17.8434\n",
      "Epoch 16/50: Validation Loss = 27.7536\n",
      "Model saved at epoch 16 with validation loss 27.7536\n",
      "Epoch 17/50: Training Loss = 16.1350\n",
      "Epoch 17/50: Validation Loss = 26.6337\n",
      "Model saved at epoch 17 with validation loss 26.6337\n",
      "Epoch 18/50: Training Loss = 14.3958\n",
      "Epoch 18/50: Validation Loss = 25.4322\n",
      "Model saved at epoch 18 with validation loss 25.4322\n",
      "Epoch 19/50: Training Loss = 12.8099\n",
      "Epoch 19/50: Validation Loss = 24.1014\n",
      "Model saved at epoch 19 with validation loss 24.1014\n",
      "Epoch 20/50: Training Loss = 11.5235\n",
      "Epoch 20/50: Validation Loss = 22.8641\n",
      "Model saved at epoch 20 with validation loss 22.8641\n",
      "Epoch 21/50: Training Loss = 10.3217\n",
      "Epoch 21/50: Validation Loss = 21.7569\n",
      "Model saved at epoch 21 with validation loss 21.7569\n",
      "Epoch 22/50: Training Loss = 9.4507\n",
      "Epoch 22/50: Validation Loss = 20.7900\n",
      "Model saved at epoch 22 with validation loss 20.7900\n",
      "Epoch 23/50: Training Loss = 8.4087\n",
      "Epoch 23/50: Validation Loss = 20.0372\n",
      "Model saved at epoch 23 with validation loss 20.0372\n",
      "Epoch 24/50: Training Loss = 7.7025\n",
      "Epoch 24/50: Validation Loss = 19.4629\n",
      "Model saved at epoch 24 with validation loss 19.4629\n",
      "Epoch 25/50: Training Loss = 6.7060\n",
      "Epoch 25/50: Validation Loss = 19.0243\n",
      "Model saved at epoch 25 with validation loss 19.0243\n",
      "Epoch 26/50: Training Loss = 5.9087\n",
      "Epoch 26/50: Validation Loss = 18.6267\n",
      "Model saved at epoch 26 with validation loss 18.6267\n",
      "Epoch 27/50: Training Loss = 5.3921\n",
      "Epoch 27/50: Validation Loss = 18.3834\n",
      "Model saved at epoch 27 with validation loss 18.3834\n",
      "Epoch 28/50: Training Loss = 4.7542\n",
      "Epoch 28/50: Validation Loss = 18.1964\n",
      "Model saved at epoch 28 with validation loss 18.1964\n",
      "Epoch 29/50: Training Loss = 4.4431\n",
      "Epoch 29/50: Validation Loss = 18.0610\n",
      "Model saved at epoch 29 with validation loss 18.0610\n",
      "Epoch 30/50: Training Loss = 4.1082\n",
      "Epoch 30/50: Validation Loss = 17.9205\n",
      "Model saved at epoch 30 with validation loss 17.9205\n",
      "Epoch 31/50: Training Loss = 3.5119\n",
      "Epoch 31/50: Validation Loss = 17.6359\n",
      "Model saved at epoch 31 with validation loss 17.6359\n",
      "Epoch 32/50: Training Loss = 3.4974\n",
      "Epoch 32/50: Validation Loss = 17.2497\n",
      "Model saved at epoch 32 with validation loss 17.2497\n",
      "Epoch 33/50: Training Loss = 3.0039\n",
      "Epoch 33/50: Validation Loss = 16.9851\n",
      "Model saved at epoch 33 with validation loss 16.9851\n",
      "Epoch 34/50: Training Loss = 2.7885\n",
      "Epoch 34/50: Validation Loss = 16.6942\n",
      "Model saved at epoch 34 with validation loss 16.6942\n",
      "Epoch 35/50: Training Loss = 2.7084\n",
      "Epoch 35/50: Validation Loss = 16.4408\n",
      "Model saved at epoch 35 with validation loss 16.4408\n",
      "Epoch 36/50: Training Loss = 2.4674\n",
      "Epoch 36/50: Validation Loss = 16.3089\n",
      "Model saved at epoch 36 with validation loss 16.3089\n",
      "Epoch 37/50: Training Loss = 2.1786\n",
      "Epoch 37/50: Validation Loss = 16.1642\n",
      "Model saved at epoch 37 with validation loss 16.1642\n",
      "Epoch 38/50: Training Loss = 1.9529\n",
      "Epoch 38/50: Validation Loss = 16.0753\n",
      "Model saved at epoch 38 with validation loss 16.0753\n",
      "Epoch 39/50: Training Loss = 1.6785\n",
      "Epoch 39/50: Validation Loss = 16.0845\n",
      "Epoch 40/50: Training Loss = 1.7099\n",
      "Epoch 40/50: Validation Loss = 16.1904\n",
      "Epoch 41/50: Training Loss = 1.3148\n",
      "Epoch 41/50: Validation Loss = 16.2827\n",
      "Epoch 42/50: Training Loss = 1.4253\n",
      "Epoch 42/50: Validation Loss = 16.3554\n",
      "Epoch 43/50: Training Loss = 1.3772\n",
      "Epoch 43/50: Validation Loss = 16.3900\n",
      "Epoch 44/50: Training Loss = 1.0171\n",
      "Epoch 44/50: Validation Loss = 16.4219\n",
      "Epoch 45/50: Training Loss = 1.1160\n",
      "Epoch 45/50: Validation Loss = 16.3872\n",
      "Epoch 46/50: Training Loss = 1.0336\n",
      "Epoch 46/50: Validation Loss = 16.3244\n",
      "Epoch 47/50: Training Loss = 0.8097\n",
      "Epoch 47/50: Validation Loss = 16.2563\n",
      "Epoch 48/50: Training Loss = 0.8188\n",
      "Epoch 48/50: Validation Loss = 16.1946\n",
      "Epoch 49/50: Training Loss = 0.7311\n",
      "Epoch 49/50: Validation Loss = 16.1357\n",
      "Epoch 50/50: Training Loss = 0.8571\n",
      "Epoch 50/50: Validation Loss = 15.9682\n",
      "Model saved at epoch 50 with validation loss 15.9682\n"
     ]
    }
   ],
   "source": [
    "bilstm_crf_5mil_no_hand = train_model_no_hand(bilstm_crf_5mil_no_hand, train_loader, valid_loader, optimizer, 50, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score      support\n",
      "\n",
      "         B-AUTHOR       0.75      0.86      0.80       190515\n",
      "         I-AUTHOR       0.90      0.97      0.93      1735612\n",
      "           B-YEAR       0.99      0.89      0.94       172556\n",
      "           I-YEAR       0.96      0.88      0.92         1350\n",
      "          B-TITLE       0.75      0.90      0.82      1815762\n",
      "          I-TITLE       0.76      0.97      0.85     18249721\n",
      "B-CONTAINER-TITLE       0.72      0.65      0.68       133714\n",
      "I-CONTAINER-TITLE       0.77      0.60      0.67      1100358\n",
      "         B-VOLUME       0.80      0.80      0.80        39419\n",
      "         I-VOLUME       0.88      0.90      0.89          155\n",
      "          B-ISSUE       0.80      0.99      0.88        13557\n",
      "          I-ISSUE       0.85      0.95      0.90          343\n",
      "           B-PAGE       0.99      0.89      0.94       157135\n",
      "           I-PAGE       0.97      0.90      0.93        29258\n",
      "           B-ISBN       0.94      0.86      0.90        45327\n",
      "           B-ISSN       0.97      0.90      0.93        10951\n",
      "      B-PUBLISHER       0.70      0.65      0.67        69554\n",
      "      I-PUBLISHER       0.99      0.80      0.88         4959\n",
      "            B-DOI       0.85      0.83      0.84        82176\n",
      "            B-URL       0.90      0.96      0.93       120729\n",
      "            I-URL       0.97      0.94      0.95         3008\n",
      "                O       0.83      0.83      0.83      3997028\n",
      "           B-PUNC       0.97      0.96      0.96      3125747\n",
      "\n",
      "         accuracy                           0.86     31098934\n",
      "        macro avg       0.87      0.86      0.86     31098934\n",
      "     weighted avg       0.80      0.93      0.86     31098934\n"
     ]
    }
   ],
   "source": [
    "evaluate_and_report_no_hand(bilstm_crf_5mil_no_hand, test_loader, label2id, id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
